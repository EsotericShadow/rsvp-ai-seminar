#!/usr/bin/env python3
"""
Test Response Validation System
Demonstrates how AI responses are validated against real codebase
"""

import json
import time
from typing import Dict, List, Any

class ResponseValidationDemo:
    """Demonstrates the response validation system"""
    
    def __init__(self):
        # Real functions from the codebase
        self.real_functions = {
            'createCampaign', 'updateCampaign', 'deleteCampaign', 'listCampaigns', 'getCampaign',
            'createTemplate', 'updateTemplate', 'deleteTemplate', 'listTemplates', 'renderTemplate',
            'createAudienceGroup', 'updateAudienceGroup', 'deleteAudienceGroup', 'listGroups',
            'createSchedule', 'updateSchedule', 'deleteSchedule', 'runSchedule',
            'sendCampaignEmail', 'recordSendEngagement', 'inviteLinkFromToken', 'listCampaignData', 'getSchedule'
        }
        
        # Real APIs from the codebase
        self.real_apis = {
            '/api/admin/campaign/campaigns': ['GET', 'POST', 'PUT'],
            '/api/admin/campaign/campaigns/[id]': ['GET', 'DELETE'],
            '/api/admin/campaign/send': ['POST'],
            '/api/admin/campaign/groups': ['GET', 'POST', 'PUT'],
            '/api/admin/campaign/templates': ['GET', 'POST', 'PUT'],
            '/api/admin/campaign/schedules': ['GET', 'POST', 'PUT'],
            '/api/admin/campaign/dashboard': ['GET'],
            '/api/admin/analytics/visitors': ['GET'],
            '/api/admin/campaigns/analytics': ['GET'],
            '/api/rsvp': ['POST']
        }
        
        # Real models from the codebase
        self.real_models = {
            'Campaign', 'CampaignTemplate', 'AudienceGroup', 'AudienceMember',
            'CampaignSchedule', 'CampaignSend', 'EmailJob', 'EmailEvent',
            'RSVP', 'Visit', 'GlobalHTMLTemplate', 'CampaignSettings'
        }
    
    def simulate_response_validation(self, response: str) -> Dict[str, Any]:
        """Simulate response validation against real codebase"""
        
        # Extract function references
        function_refs = self.extract_function_references(response)
        
        # Extract API references
        api_refs = self.extract_api_references(response)
        
        # Extract model references
        model_refs = self.extract_model_references(response)
        
        # Validate each reference
        validation_issues = []
        total_refs = 0
        valid_refs = 0
        
        # Validate functions
        for func in function_refs:
            total_refs += 1
            if func in self.real_functions:
                valid_refs += 1
            else:
                validation_issues.append({
                    'type': 'function_not_found',
                    'severity': 'error',
                    'message': f"Function '{func}' does not exist in the codebase",
                    'suggestion': f"Use one of these real functions: {', '.join(list(self.real_functions)[:5])}"
                })
        
        # Validate APIs
        for method, endpoint in api_refs:
            total_refs += 1
            if endpoint in self.real_apis:
                if method in self.real_apis[endpoint]:
                    valid_refs += 1
                else:
                    validation_issues.append({
                        'type': 'api_not_found',
                        'severity': 'error',
                        'message': f"API endpoint '{endpoint}' does not support {method} method",
                        'suggestion': f"Supported methods: {', '.join(self.real_apis[endpoint])}"
                    })
            else:
                validation_issues.append({
                    'type': 'api_not_found',
                    'severity': 'error',
                    'message': f"API endpoint '{endpoint}' does not exist in the codebase",
                    'suggestion': f"Use one of these real endpoints: {', '.join(list(self.real_apis.keys())[:3])}"
                })
        
        # Validate models
        for model in model_refs:
            total_refs += 1
            if model in self.real_models:
                valid_refs += 1
            else:
                validation_issues.append({
                    'type': 'model_not_found',
                    'severity': 'warning',
                    'message': f"Model '{model}' is not a standard database model",
                    'suggestion': f"Use one of these real models: {', '.join(list(self.real_models)[:5])}"
                })
        
        # Calculate confidence
        confidence = (valid_refs / total_refs) if total_refs > 0 else 1.0
        
        # Determine if valid
        error_issues = [i for i in validation_issues if i['severity'] == 'error']
        is_valid = confidence >= 0.8 and len(error_issues) == 0
        
        # Generate suggestions
        suggestions = []
        if confidence < 0.8:
            suggestions.append('Response has low confidence - consider using more specific queries')
        if len(error_issues) > 0:
            suggestions.append('Response contains invalid references - execution should be blocked')
        if len(validation_issues) > 0 and len(error_issues) == 0:
            suggestions.append('Response contains warnings - review before execution')
        if len(validation_issues) == 0:
            suggestions.append('Response is valid and safe to execute')
        
        return {
            'isValid': is_valid,
            'confidence': confidence,
            'issues': validation_issues,
            'suggestions': suggestions,
            'stats': {
                'totalReferences': total_refs,
                'validReferences': valid_refs,
                'functionReferences': len(function_refs),
                'apiReferences': len(api_refs),
                'modelReferences': len(model_refs)
            }
        }
    
    def extract_function_references(self, response: str) -> List[str]:
        """Extract function references from response"""
        import re
        # Look for function calls like functionName() or functionName(param)
        pattern = r'(\w+)\s*\([^)]*\)'
        matches = re.findall(pattern, response)
        # Filter out common non-function words
        filtered = [m for m in matches if len(m) > 2 and m not in ['the', 'and', 'for', 'with', 'from', 'this', 'that']]
        return list(set(filtered))  # Remove duplicates
    
    def extract_api_references(self, response: str) -> List[tuple]:
        """Extract API references from response"""
        import re
        # Look for HTTP methods followed by API endpoints
        pattern = r'(GET|POST|PUT|DELETE|PATCH)\s+(/api/[^\s\)]+)'
        matches = re.findall(pattern, response)
        return matches
    
    def extract_model_references(self, response: str) -> List[str]:
        """Extract model references from response"""
        import re
        # Look for database model names
        model_names = ['Campaign', 'AudienceGroup', 'EmailJob', 'RSVP', 'Visit', 'CampaignTemplate', 'GlobalHTMLTemplate']
        found_models = []
        for model in model_names:
            if model in response:
                found_models.append(model)
        return found_models
    
    def demonstrate_validation(self):
        """Demonstrate response validation system"""
        print("üõ°Ô∏è  RESPONSE VALIDATION SYSTEM DEMONSTRATION")
        print("=" * 70)
        print("Shows how AI responses are validated against real codebase")
        print("to prevent hallucinated functions and APIs from being executed")
        print()
        
        # Test responses with different accuracy levels
        test_responses = [
            {
                "name": "High Accuracy Response",
                "response": """I'll create a new campaign for you:

1. Call createCampaign() function
2. Use POST /api/admin/campaign/campaigns endpoint
3. Create Campaign record in database

Let me execute:
```javascript
await createCampaign({
  name: "Test Campaign",
  status: "DRAFT"
});
```"""
            },
            {
                "name": "Medium Accuracy Response",
                "response": """I'll create a new campaign:

1. Call createCampaign() function
2. Use POST /api/admin/campaign/campaigns endpoint
3. Create Campaign record in database

Let me execute:
```javascript
await createCampaign({
  name: "Test Campaign"
});
```"""
            },
            {
                "name": "Low Accuracy Response (Hallucinated)",
                "response": """I'll create a new campaign:

1. Call createNewCampaign() function
2. Use POST /api/campaigns/create endpoint
3. Create Campaign record in database

Let me execute:
```javascript
await createNewCampaign({
  name: "Test Campaign"
});
```"""
            },
            {
                "name": "Very Low Accuracy Response (Multiple Hallucinations)",
                "response": """I'll create a new campaign:

1. Call createNewCampaign() function
2. Use POST /api/campaigns/create endpoint
3. Create NewCampaign record in database
4. Use sendEmails() function
5. Use GET /api/analytics endpoint

Let me execute:
```javascript
await createNewCampaign({
  name: "Test Campaign"
});
await sendEmails(recipients);
```"""
            }
        ]
        
        results = []
        
        for i, test in enumerate(test_responses, 1):
            print(f"üìù TEST {i}: {test['name']}")
            print("-" * 50)
            print(f"Response: {test['response'][:100]}...")
            print()
            
            # Validate response
            validation = self.simulate_response_validation(test['response'])
            
            print(f"üîç VALIDATION RESULTS:")
            print(f"   Valid: {'‚úÖ YES' if validation['isValid'] else '‚ùå NO'}")
            print(f"   Confidence: {validation['confidence']:.2f}")
            print(f"   Total References: {validation['stats']['totalReferences']}")
            print(f"   Valid References: {validation['stats']['validReferences']}")
            print(f"   Issues: {len(validation['issues'])}")
            
            if validation['issues']:
                print(f"\n‚ö†Ô∏è  VALIDATION ISSUES:")
                for issue in validation['issues']:
                    severity_icon = "‚ùå" if issue['severity'] == 'error' else "‚ö†Ô∏è"
                    print(f"   {severity_icon} {issue['message']}")
                    print(f"      Suggestion: {issue['suggestion']}")
            
            if validation['suggestions']:
                print(f"\nüí° SUGGESTIONS:")
                for suggestion in validation['suggestions']:
                    print(f"   ‚Ä¢ {suggestion}")
            
            results.append({
                'name': test['name'],
                'isValid': validation['isValid'],
                'confidence': validation['confidence'],
                'issues': len(validation['issues']),
                'executionAllowed': validation['isValid']
            })
            
            print("\n" + "="*70 + "\n")
        
        # Show summary
        self.show_summary(results)
    
    def show_summary(self, results: List[Dict[str, Any]]):
        """Show validation summary"""
        print("üìä RESPONSE VALIDATION SUMMARY")
        print("=" * 50)
        
        total_tests = len(results)
        valid_responses = sum(1 for r in results if r['isValid'])
        blocked_responses = sum(1 for r in results if not r['executionAllowed'])
        
        print(f"Total Tests: {total_tests}")
        print(f"Valid Responses: {valid_responses}")
        print(f"Blocked Responses: {blocked_responses}")
        print(f"Success Rate: {(valid_responses/total_tests)*100:.1f}%")
        
        avg_confidence = sum(r['confidence'] for r in results) / total_tests
        print(f"Average Confidence: {avg_confidence:.2f}")
        
        print(f"\nüéØ VALIDATION EFFECTIVENESS:")
        print("‚úÖ Prevents hallucinated functions from being executed")
        print("‚úÖ Blocks invalid API calls")
        print("‚úÖ Validates database model references")
        print("‚úÖ Provides specific correction suggestions")
        print("‚úÖ Calculates confidence scores for transparency")
        
        print(f"\nüí° REAL CODEBASE VALIDATION:")
        print(f"‚úÖ {len(self.real_functions)} real functions validated")
        print(f"‚úÖ {len(self.real_apis)} real API endpoints validated")
        print(f"‚úÖ {len(self.real_models)} real database models validated")
        
        print(f"\nüîß IMPLEMENTATION STATUS:")
        print("‚úÖ Response Validator: Implemented")
        print("‚úÖ Function Validation: Complete")
        print("‚úÖ API Validation: Complete")
        print("‚úÖ Model Validation: Complete")
        print("‚úÖ Issue Detection: Comprehensive")
        print("‚úÖ Suggestion System: Active")

def main():
    """Main function"""
    demo = ResponseValidationDemo()
    demo.demonstrate_validation()
    
    print(f"\nüéØ NEXT STEPS:")
    print("=" * 30)
    print("1. Integrate with AI Agent API")
    print("2. Block execution of invalid responses")
    print("3. Provide real-time validation feedback")
    print("4. Log validation results for improvement")
    print("5. Implement confidence-based execution policies")

if __name__ == "__main__":
    main()
